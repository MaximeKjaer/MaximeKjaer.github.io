---
title: CS-452 Foundations of Software
description: "My notes from the CS-452 Foundations of Software course given at EPFL, in the 2018 autumn semester (MA1)"
unlisted: true
---

* TOC
{:toc}

## Writing a parser with parser combinators
In Scala, you can (ab)use the operator overload to create an embedded DSL (EDSL) for grammars. While a grammar may look as follows in a grammar description language (Bison, Yak, ANTLR, ...):

{% highlight antlr linenos %}
Expr ::= Term {'+' Term | 'âˆ’' Term}
Term ::= Factor {'âˆ—' Factor | '/' Factor}
Factor ::= Number | '(' Expr ')'
{% endhighlight %}

In Scala, we can model it as follows:

{% highlight scala linenos %}
def expr: Parser[Any] = term ~ rep("+" ~ term | "âˆ’" ~ term)
def term: Parser[Any] = factor ~ rep("âˆ—" ~ factor | "/" ~ factor)
def factor: Parser[Any] = "(" ~ expr ~ ")" | numericLit
{% endhighlight %}

This is perhaps a little less elegant, but allows us to encode it directly into our language, which is often useful for interop.

The `~`, `|`, `rep` and `opt` are **parser combinators**. These are primitives with which we can construct a full parser for the grammar of our choice.

### Boilerplate

First, let's define a class `ParseResult[T]` as an ad-hoc monad; parsing can either succeed or fail:

{% highlight scala linenos %}
sealed trait ParseResult[T]
case class Success[T](result: T, in: Input) extends ParseResult[T]
case class Failure(msg : String, in: Input) extends ParseResult[Nothing]
{% endhighlight %}

> ðŸ‘‰ `Nothing` is the bottom type in Scala; it contains no members, and nothing can extend it

Let's also define the tokens produced by the lexer (which we won't define) as case classes extending `Token`:

{% highlight scala linenos %}
sealed trait Token
case class Keyword(chars: String) extends Token
case class NumericLit(chars: String) extends Token
case class StringLit(chars: String) extends Token
case class Identifier(chars: String) extends Token
{% endhighlight %}

Input into the parser is then a lazy stream of tokens (with positions for error diagnostics, which we'll omit here):

{% highlight scala linenos %}
type Input = Reader[Token]
{% endhighlight %}

We can then define a standard, sample parser which looks as follows on the type-level:

{% highlight scala linenos %}
class StandardTokenParsers {
    type Parser = Input => ParseResult
}
{% endhighlight %}

### The basic idea
For each language (defined by a grammar symbol `S`), define a function `f` that, given an input stream `i` (with tail `i'`):

- if a prefix of `i` is in `S`, return `Success(Pair(x, i'))`, where `x` is a result for `S`
- otherwise, return `Failure(msg, i)`, where `msg` is an error message string

The first is called *success*, the second is *failure*. We can compose operations on this somewhat conveniently, like we would on a monad (like `Option`).

### Simple parser primitives
All of the above boilerplate allows us to define a parser, which succeeds if the first token in the input satisfies some given predicate `pred`. When it succeeds, it reads the token string, and splits the input there.

{% highlight scala linenos %}
def token(kind: String)(pred: Token => boolean) = new Parser[String] {
    def apply(in : Input) =
        if (pred(in.head)) Success(in.head.chars, in.tail)
        else Failure(kind + " expected ", in)
}
{% endhighlight %}

We can use this to define a keyword parser:

{% highlight scala linenos %}
implicit def keyword(chars: String) = token("'" + chars + "'") {
    case Keyword(chars1) => chars == chars1
    case _ => false
}
{% endhighlight %}

Marking it as `implicit` allows us to write keywords as normal strings, where we can omit the `keyword` call (this helps us simplify the notation in our DSL; we can write `"if"` instead of `keyword("if")`).

We can make other parsers for our other case classes quite simply:

{% highlight scala linenos %}
def numericLit = token("number")( .isInstanceOf[NumericLit])
def stringLit = token("string literal")( .isInstanceOf[StringLit])
def ident = token("identifier")( .isInstanceOf[Identifier])
{% endhighlight %}

### Parser combinators
We are going to define the following parser combinators:

- `~`: sequential composition
- `<~`, `>~`: sequential composition, keeping left / right only
- `|`: alternative
- `opt(X)`: option (like a `?` quantifier in a regex)
- `rep(X)`: repetition (like a `*` quantifier in a regex)
- `repsep(P, Q)`: interleaved repetition
- `^^`: result conversion (like a `map` on an `Option`)
- `^^^`: constant result (like a `map` on an `Option`, but returning a constant value regardless of result)

But first, we'll write some very basic parser combinators: `success` and `failure`, that respectively always succeed and always fail:

{% highlight scala linenos %}
def success[T](result: T) = new Parser[T] {
    def apply(in: Input) = Success(result, in)
}

def failure(msg: String) = new Parser[Nothing] {
    def apply(in: Input) = Failure(msg, in)
}
{% endhighlight %}

All of the above are methods on a `Parser[T]` class. Thanks to infix space notation in Scala, we can denote `x.y(z)` as `x y z`, which allows us to simplify our DSL notation; for instance `A ~ B` corresponds to `A.~(B)`.

{% highlight scala linenos %}
abstract class Parser[T] {
    // An abstract method that defines the parser function
    def apply(in : Input): ParseResult

    def ~[U](rhs: Parser[U]) = new Parser[T ~ U] {
        def apply(in: Input) = Parser.this(in) match {
            case Success(x, tail) => rhs(tail) match {
                case Success(y, rest) => Success(new ~(x, y), rest)
                case failure => failure
            }
            case failure => failure
        }
    }

    def |(rhs: => Parser[T]) = new Parser[T] {
        def apply(in : Input) = Parser.this(in) match {
            case s1 @ Success(_, _) => s1
            case failure => rhs(in)
        }
    }

    def ^^[U](f: T => U) = new Parser[U] {
        def apply(in : Input) = Parser.this(in) match {
            case Success(x, tail) => Success(f(x), tail)
            case x => x
        }
    }

    def ^^^[U](r: U): Parser[U] = ^^(x => r)
}
{% endhighlight %}

> ðŸ‘‰ In Scala, `T ~ U` is syntactic sugar for `~[T, U]`, which is the type of the case class we'll define below

For the `~` combinator, when everything works, we're using `~`, a case class that is equivalent to `Pair`, but prints the way we want to and allows for the concise type-level notation above.

{% highlight scala linenos %}
case class ~[T, U](_1 : T, _2 : U) {
    override def toString = "(" + _1 + " ~ " + _2 +")"
}
{% endhighlight %}

At this point, we thus have **two** different meanings for `~`: a *function* `~` that produces a `Parser`, and the `~(a, b)` *case class* pair that this parser returns (all of this is encoded in the function signature of the `~` function).

Note that the `|` combinator takes the right-hand side parser as a call-by-name argument. This is because we don't want to evaluate it unless it is strictly neededâ€”that is, if the left-hand side fails.

`^^` is like a `map` operation on `Option`; `P ^^ f` succeeds iff `P` succeeds, in which case it applies the transformation `f` on the result of P. Otherwise, it fails.

### Shorthands

We can now define shorthands for common combinations of parser combinators:

{% highlight scala linenos %}
def opt[T](p : Parser[T]): Parser[Option[T]] = p ^^ Some | success(None)

def rep[T](p : Parser[T]): Parser[List[T]] = 
    p ~ rep(p) ^^ { case x ~ xs => x :: xs } | success(Nil)

def repsep[T, U](p : Parser[T], q : Parser[U]): Parser[List[T]] = 
    p ~ rep(q ~> p) ^^ { case r ~ rs => r :: rs } | success(Nil)
{% endhighlight %}

Note that none of the above can fail. They may, however, return `None` or `Nil` wrapped in `success`.


As an exercise, we can implement the `rep1(P)` parser combinator, which corresponds to the `+` regex quantifier:

{% highlight scala linenos %}
def rep1[T](p: Parser[T]) = p ~ rep(p)
{% endhighlight %}

### Example: JSON parser

We did not mention `lexical.delimiters` and `lexical.reserved` in the above, and for the sake of brevity, we omit the implementation of `stringLit` and `numericLit`.

{% highlight scala linenos %}
object JSON extends StandardTokenParsers {
    lexical.delimiters += ("{", "}", "[", "]", ":")
    lexical.reserved += ("null", "true", "false")

    // Return Map
    def obj: Parser[Any] = "{" ~ repsep(member, ",") ~ "}" ^^ (ms => Map() ++ ms)

    // Return List
    def arr: Parser[Any] = "[" ~> repsep(value, ",") <~ "]"

    // Return name/value pair:
    def member: Parser[Any] = stringLit ~ ":" ~ value ^^ {
        case name ~ ":" ~ value => (name, value) 
    }

    // Return correct Scala type
    def value: Parser[Any] =
          obj 
        | arr 
        | stringLit
        | numericLit ^^ (_.toInt)
        | "null" ^^^ null
        | "true" ^^^ true
        | "false" ^^^ false
}
{% endhighlight %}

### The trouble with left-recursion

Parser combinators work top-down and therefore do not allow for left-recursion. For example, the following would go into an infinite loop, where the parser keeps recursively matching the same token unto `expr`:

{% highlight scala linenos %}
def expr = expr ~ "-" ~ term
{% endhighlight %}

Let's take a look at an arithmetic expression parser:

{% highlight scala linenos %}
object Arithmetic extends StandardTokenParsers {
    lexical.delimiters ++= List("(", ")", "+", "âˆ’", "âˆ—", "/")
    def expr: Parser[Any] = term ~ rep("+" ~ term | "âˆ’" ~ term)
    def term: Parser[Any] = factor ~ rep("âˆ—" ~ factor | "/" ~ factor)
    def factor: Parser[Any] = "(" ~ expr ~ ")" | numericLit
}
{% endhighlight %}

This definition of `expr`, namely `term ~ rep("-" ~ term)` produces a right-leaning tree. For instance, `1 - 2 - 3` produces `1 ~ List("-" ~ 2, ~ "-" ~ 3)`. 

The solution is to combine calls to `rep` with a final foldLeft on the list:

{% highlight scala linenos %}
object Arithmetic extends StandardTokenParsers {
    lexical.delimiters ++= List("(", ")", "+", "âˆ’", "âˆ—", "/")
    def expr: Parser[Any] = term ~ rep("+" ~ term | "âˆ’" ~ term) ^^ reduceList
    def term: Parser[Any] = factor ~ rep("âˆ—" ~ factor | "/" ~ factor) ^^ reduceList
    def factor: Parser[Any] = "(" ~ expr ~ ")" | numericLit

    private def reduceList(list: Expr ~ List[String ~ Expr]): Expr = list match {
        case x ~ xs => (x foldLeft ps)(reduce)
    }

    private def reduce(x: Int, r: String ~ Int) = r match {
        case "+" ~ y => x + y
        case "âˆ’" ~ y => x âˆ’ y
        case "âˆ—" ~ y => x âˆ— y
        case "/" ~ y => x / y
        case => throw new MatchError("illegal case: " + r)
    }
}
{% endhighlight %}

> ðŸ‘‰ It used to be that the standard library contained parser combinators, but those are now a [separate module](https://github.com/scala/scala-parser-combinators). This module contains a `chainl` (chain-left) method that reduces after a `rep` for you.

